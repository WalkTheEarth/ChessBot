# ğŸ§  ChessBot - AI Chess Engine Trainer

A sophisticated reinforcement learning system that trains neural networks to play chess using Deep Q-Learning, self-play, and engine opposition.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Start training (self-play)
python main.py --games 100 --threads 2

# Train against Stockfish
python main.py --games 1000 --difficulty 5 --engine-path "C:/Stockfish/stockfish.exe" --threads 4
```

## ğŸ“š Documentation

### **Getting Started**
- **[Quick Start Guide](docs/QUICK_START.md)** - Get training in under 5 minutes
- **[Full Documentation](docs/README.md)** - Comprehensive guide with all features
- **[API Reference](docs/API_DOCUMENTATION.md)** - Complete API documentation

### **Key Features**
- ğŸ§  **Deep Q-Network (DQN)** with CNN architecture
- âš¡ **Multi-threaded training** (up to 8x speedup)
- ğŸ® **Self-play and engine opposition** training modes
- ğŸ“Š **Real-time progress monitoring** with Rich UI
- ğŸ’¾ **Automatic checkpointing** and model saving

## ğŸ¯ Training Examples

### Basic Self-Play
```bash
python main.py --games 1000 --threads 4
```

### Engine Opposition
```bash
python main.py --games 1000 --difficulty 8 --engine-path "C:/Stockfish/stockfish.exe" --threads 6
```

### Mixed Training
```bash
python main.py --games 2000 --difficulty 10 --self-play-ratio 0.7 --engine-path "C:/Stockfish/stockfish.exe" --threads 8
```

## ğŸ“ Project Structure

```
ChessBot/
â”œâ”€â”€ ğŸ§  Core AI Components
â”‚   â”œâ”€â”€ agent.py          # DQN agent with experience replay
â”‚   â”œâ”€â”€ model.py          # CNN neural network architecture
â”‚   â””â”€â”€ chess_env.py      # Chess environment & state representation
â”‚
â”œâ”€â”€ ğŸ® Training & Execution
â”‚   â”œâ”€â”€ main.py           # Multi-threaded CLI training interface
â”‚   â”œâ”€â”€ train.py          # Training loop and game simulation
â”‚   â””â”€â”€ uci_handler.py    # Stockfish/UCI engine integration
â”‚
â”œâ”€â”€ ğŸ¯ Play Against AI
â”‚   â”œâ”€â”€ play_chess.py     # GUI chess game (tkinter)
â”‚   â”œâ”€â”€ play_chess_cli.py # Command-line chess game
â”‚   â”œâ”€â”€ launch_game.py    # Game launcher with dependency check
â”‚   â””â”€â”€ play_chess.bat    # Windows batch file launcher
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md         # Comprehensive documentation
â”‚   â”œâ”€â”€ QUICK_START.md    # Quick start guide
â”‚   â””â”€â”€ API_DOCUMENTATION.md # Complete API reference
â”‚
â”œâ”€â”€ ğŸ’¾ Model Storage
â”‚   â”œâ”€â”€ checkpoint_*.pth  # Training checkpoints
â”‚   â”œâ”€â”€ final_model.pth   # Final trained model
â”‚   â””â”€â”€ Model1/, Model2/, Model3/  # Alternative model versions
â”‚
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸ® Usage

### **Play Against Your Trained AI**

#### **Easy Launch (Recommended)**
```bash
# Windows: Double-click play_chess.bat
# Or run the launcher
python launch_game.py
```

#### **Direct Launch**
```bash
# GUI Version (Recommended)
pip install Pillow cairosvg  # Install GUI dependencies
python play_chess.py

# Command Line Version
python play_chess_cli.py
```

**Features:**
- ğŸ¯ **Model Selection**: Choose from your trained checkpoints
- ğŸšï¸ **AI Difficulty**: Adjust AI strength (0=best, 0.5=random)
- â†©ï¸ **Undo Moves**: Take back moves if needed
- ğŸ“Š **Move History**: See all moves played
- ğŸ¨ **Visual Board**: Click to move pieces (GUI version)

### **Training Your AI**

#### **Command Line Arguments**

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--games` | int | 1000 | Total number of training games |
| `--threads` | int | 4 | Parallel game threads (1-8 recommended) |
| `--difficulty` | int | 5 | Stockfish skill level (0-20, higher = stronger) |
| `--self-play-ratio` | float | 0.7 | Ratio of self-play vs engine games (0.0-1.0) |
| `--load-model` | str | None | Path to existing model checkpoint |
| `--engine-path` | str | None | Path to Stockfish executable |

### Training Progress

During training, you'll see real-time updates:
```
Game  250/1000 ğŸ† | W: 85 L: 120 D: 45 | WR: 34.0% | Îµ:0.7750 | Moves: 47 | Speed:3.2g/s | ETA:3.9m
```

**Legend:**
- ğŸ†/ğŸ’€/ğŸ¤ = Win/Loss/Draw
- WR = Win Rate
- Îµ = Exploration rate (starts at 1.0, decays to 0.01)
- Speed = Games per second

## ğŸ§  Neural Network Architecture

- **Input**: 12Ã—8Ã—8 tensor (6 piece types Ã— 2 colors)
- **Architecture**: 3-layer CNN + fully connected layers
- **Output**: Single Q-value for position evaluation
- **Training**: Experience replay with target network

## ğŸ“ˆ Expected Performance

| Training Phase | Games | Win Rate vs Difficulty 5 | Key Learning |
|----------------|-------|---------------------------|--------------|
| **Exploration** | 0-500 | ~20-30% | Basic rules, piece movement |
| **Development** | 500-2000 | ~30-45% | Tactical patterns, piece coordination |
| **Refinement** | 2000-5000 | ~45-60% | Strategic planning, endgames |
| **Mastery** | 5000+ | ~60%+ | Advanced tactics, opening theory |

## ğŸ› Troubleshooting

### Common Issues
- **"ModuleNotFoundError"**: Run `pip install -r requirements.txt`
- **"Engine connection failed"**: Check Stockfish path or use self-play
- **"CUDA out of memory"**: Reduce threads or use CPU-only mode
- **Training not progressing**: Increase games or adjust difficulty

### Getting Help
1. **Read the [Quick Start Guide](docs/QUICK_START.md)** for immediate help
2. **Check the [Full Documentation](docs/README.md)** for comprehensive troubleshooting
3. **Review the [API Documentation](docs/API_DOCUMENTATION.md)** for technical details

## ğŸš€ Future Enhancements

- [ ] Policy gradient methods (PPO/A3C)
- [ ] Monte Carlo Tree Search integration
- [ ] Opening book integration
- [ ] Web interface for visualization
- [ ] ELO rating tracking
- [ ] Multi-GPU support

## ğŸ“„ License

This project is released under the **MIT License**. Feel free to use, modify, and distribute.

## ğŸ™ Acknowledgments

- **PyTorch** - Deep learning framework
- **python-chess** - Chess library and UCI protocol
- **Stockfish** - Open source chess engine
- **Rich** - Beautiful terminal interfaces
- **AlphaZero** - Inspiration for self-play RL

---

## ğŸ‰ Ready to Train Your Chess AI?

```bash
# Quick start command
python main.py --games 100 --threads 4

# Full training session
python main.py --games 2000 --threads 6 --difficulty 8 --engine-path "C:/Stockfish/stockfish.exe"
```

**Happy Training! May your neural network achieve chess mastery! â™Ÿï¸ğŸ§ ğŸš€**

*For detailed documentation, see the [docs/](docs/) folder.*
